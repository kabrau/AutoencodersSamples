{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Reshape, UpSampling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12544)             1618176   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 1)         289       \n",
      "=================================================================\n",
      "Total params: 3,261,505\n",
      "Trainable params: 3,261,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_img = Input(input_shape)  \n",
    "\n",
    "if True:\n",
    "    x = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    encoded = Dropout(0.5)(x)\n",
    "\n",
    "    x = Dense(12544, activation='relu')(encoded) #contrario de Flatten()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Reshape((14,14,64))(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    \n",
    "else:\n",
    "    x = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    #x = Flatten()(x)\n",
    "    #x = Dense(128, activation='relu')(x)\n",
    "    encoded = x #Dropout(0.5)(x)\n",
    "\n",
    "    #x = Dense(12544, activation='relu')(encoded) #contrario de Flatten()(x)\n",
    "    #x = Dropout(0.25)(x)\n",
    "    #x = Reshape((14,14,64))(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    #x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "#autoencoder.compile(loss=keras.losses.categorical_crossentropy,\n",
    "#              optimizer=keras.optimizers.Adadelta(),\n",
    "#              metrics=['accuracy'])\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "print(autoencoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 53s 875us/step - loss: 0.1487 - val_loss: 0.1050\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 52s 860us/step - loss: 0.1296 - val_loss: 0.1008\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 52s 863us/step - loss: 0.1254 - val_loss: 0.0990\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 52s 864us/step - loss: 0.1226 - val_loss: 0.0970\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 52s 862us/step - loss: 0.1205 - val_loss: 0.1008\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 53s 880us/step - loss: 0.1188 - val_loss: 0.1028\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 52s 867us/step - loss: 0.1174 - val_loss: 0.1117\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 52s 868us/step - loss: 0.1160 - val_loss: 0.1101\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 52s 866us/step - loss: 0.1150 - val_loss: 0.1143\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 52s 864us/step - loss: 0.1139 - val_loss: 0.1251\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    autoencoder.load_weights(\"autoencoder_weights.HDF5\")\n",
    "else:    \n",
    "    autoencoder.fit(x_train, x_train,\n",
    "                epochs=10,\n",
    "                batch_size=8,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "    print(autoencoder.save_weights(\"autoencoder_weights.HDF5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.07623082 -0.12032484  0.3973239  -0.3366975   0.14241152\n",
      "   -0.05673959  0.0844188   0.00570139 -0.14081125  0.15421757\n",
      "   -0.1917015   0.24459676 -0.29250637  0.0634649  -0.15459545\n",
      "   -0.08232243 -0.3602249  -0.17957644 -0.3409233  -0.39043853\n",
      "   -0.43835434  0.18992577  0.02360842  0.20545992 -0.2596323\n",
      "   -0.208677    0.00589803 -0.00967088 -0.15173426 -0.02905618\n",
      "   -0.21358559  0.01682538]]\n",
      "\n",
      " [[-0.17867354 -0.07504158  0.05513505  0.04943751  0.01186244\n",
      "   -0.06974396 -0.10617781 -0.03703439 -0.01056977  0.27876037\n",
      "   -0.01569174  0.17649482 -0.00075268  0.12637718  0.01334574\n",
      "   -0.12163792 -0.17849211 -0.06328982  0.24032484 -0.09484605\n",
      "   -0.1033796  -0.01214933  0.08414569 -0.02863465 -0.10580882\n",
      "    0.00571417  0.1344088   0.14858988 -0.1556052  -0.00534379\n",
      "   -0.22810127  0.02708792]]\n",
      "\n",
      " [[-0.20064028 -0.13947819 -0.0716333   0.133561   -0.1296077\n",
      "   -0.29020837 -0.21206509 -0.29857078 -0.09959412  0.18735065\n",
      "   -0.18726988  0.04675273 -0.10878522 -0.00844475  0.2215725\n",
      "   -0.18475497  0.05852271 -0.19581656 -0.135387    0.07885138\n",
      "    0.01194794  0.32511345 -0.16763848  0.19836442  0.19235837\n",
      "    0.25017422  0.16357052  0.2133326  -0.21221893  0.07977854\n",
      "   -0.1394275  -0.07303014]]]\n"
     ]
    }
   ],
   "source": [
    "print(autoencoder.get_weights()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c8997da58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1+ n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.topology.InputLayer object at 0x0000010C911EDBE0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000010C911EDC18>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000010C911EDE80>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000010C911EDEB8>\n",
      "<keras.layers.core.Dropout object at 0x0000010C911F6D30>\n",
      "<keras.layers.core.Flatten object at 0x0000010C911D5CF8>\n",
      "<keras.layers.core.Dense object at 0x0000010C911F76A0>\n",
      "<keras.layers.core.Dropout object at 0x0000010C91231BA8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,642,378\n",
      "Trainable params: 17,802\n",
      "Non-trainable params: 1,624,576\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#x = Flatten()(encoded)\n",
    "x = Dense(128, activation='relu')(encoded) #(x)\n",
    "x = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "classModel = Model(input_img, x)\n",
    "\n",
    "for layer in classModel.layers[0:8]:\n",
    "    layer.trainable = False\n",
    "    print(layer)\n",
    "\n",
    "\n",
    "classModel.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "#classModel.compile(optimizer='adadelta', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "print(classModel.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.07623082 -0.12032484  0.3973239  -0.3366975   0.14241152\n",
      "   -0.05673959  0.0844188   0.00570139 -0.14081125  0.15421757\n",
      "   -0.1917015   0.24459676 -0.29250637  0.0634649  -0.15459545\n",
      "   -0.08232243 -0.3602249  -0.17957644 -0.3409233  -0.39043853\n",
      "   -0.43835434  0.18992577  0.02360842  0.20545992 -0.2596323\n",
      "   -0.208677    0.00589803 -0.00967088 -0.15173426 -0.02905618\n",
      "   -0.21358559  0.01682538]]\n",
      "\n",
      " [[-0.17867354 -0.07504158  0.05513505  0.04943751  0.01186244\n",
      "   -0.06974396 -0.10617781 -0.03703439 -0.01056977  0.27876037\n",
      "   -0.01569174  0.17649482 -0.00075268  0.12637718  0.01334574\n",
      "   -0.12163792 -0.17849211 -0.06328982  0.24032484 -0.09484605\n",
      "   -0.1033796  -0.01214933  0.08414569 -0.02863465 -0.10580882\n",
      "    0.00571417  0.1344088   0.14858988 -0.1556052  -0.00534379\n",
      "   -0.22810127  0.02708792]]\n",
      "\n",
      " [[-0.20064028 -0.13947819 -0.0716333   0.133561   -0.1296077\n",
      "   -0.29020837 -0.21206509 -0.29857078 -0.09959412  0.18735065\n",
      "   -0.18726988  0.04675273 -0.10878522 -0.00844475  0.2215725\n",
      "   -0.18475497  0.05852271 -0.19581656 -0.135387    0.07885138\n",
      "    0.01194794  0.32511345 -0.16763848  0.19836442  0.19235837\n",
      "    0.25017422  0.16357052  0.2133326  -0.21221893  0.07977854\n",
      "   -0.1394275  -0.07303014]]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(classModel.get_weights()[0][0])\n",
    "print(classModel.get_weights()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 0s 271us/step - loss: 0.4228 - acc: 0.8750 - val_loss: 0.2907 - val_acc: 0.9105\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 0s 262us/step - loss: 0.4185 - acc: 0.8700 - val_loss: 0.2895 - val_acc: 0.9113\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 0s 258us/step - loss: 0.3969 - acc: 0.8720 - val_loss: 0.2858 - val_acc: 0.9118\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 0s 262us/step - loss: 0.3964 - acc: 0.8870 - val_loss: 0.2815 - val_acc: 0.9158\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 0s 266us/step - loss: 0.4095 - acc: 0.8640 - val_loss: 0.2866 - val_acc: 0.9113\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 0s 261us/step - loss: 0.3823 - acc: 0.8790 - val_loss: 0.2759 - val_acc: 0.9144\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 0s 257us/step - loss: 0.3953 - acc: 0.8810 - val_loss: 0.2742 - val_acc: 0.9168\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 0s 264us/step - loss: 0.4057 - acc: 0.8740 - val_loss: 0.2750 - val_acc: 0.9182\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 0s 257us/step - loss: 0.4085 - acc: 0.8680 - val_loss: 0.2746 - val_acc: 0.9142\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 0s 263us/step - loss: 0.4086 - acc: 0.8750 - val_loss: 0.2810 - val_acc: 0.9126\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 0s 268us/step - loss: 0.3789 - acc: 0.8710 - val_loss: 0.2699 - val_acc: 0.9180\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 0s 256us/step - loss: 0.3832 - acc: 0.8850 - val_loss: 0.2745 - val_acc: 0.9159\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 0s 261us/step - loss: 0.3770 - acc: 0.8780 - val_loss: 0.2721 - val_acc: 0.9163\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 0s 263us/step - loss: 0.3711 - acc: 0.8700 - val_loss: 0.2645 - val_acc: 0.9196\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 0s 258us/step - loss: 0.3752 - acc: 0.8750 - val_loss: 0.2709 - val_acc: 0.9184\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 0s 261us/step - loss: 0.4044 - acc: 0.8780 - val_loss: 0.2671 - val_acc: 0.9181\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 0s 270us/step - loss: 0.3984 - acc: 0.8810 - val_loss: 0.2696 - val_acc: 0.9190\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 0s 258us/step - loss: 0.3664 - acc: 0.8720 - val_loss: 0.2658 - val_acc: 0.9193\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 0s 259us/step - loss: 0.3711 - acc: 0.8900 - val_loss: 0.2631 - val_acc: 0.9211\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 0s 258us/step - loss: 0.3885 - acc: 0.8720 - val_loss: 0.2680 - val_acc: 0.9167\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 0s 259us/step - loss: 0.3823 - acc: 0.8810 - val_loss: 0.2646 - val_acc: 0.9188\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 0s 256us/step - loss: 0.3716 - acc: 0.8860 - val_loss: 0.2736 - val_acc: 0.9158\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 0s 258us/step - loss: 0.3672 - acc: 0.8740 - val_loss: 0.2633 - val_acc: 0.9204\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 0s 261us/step - loss: 0.3997 - acc: 0.8750 - val_loss: 0.2648 - val_acc: 0.9188\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 0s 258us/step - loss: 0.3785 - acc: 0.8800 - val_loss: 0.2608 - val_acc: 0.9205\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 0s 257us/step - loss: 0.3752 - acc: 0.8700 - val_loss: 0.2588 - val_acc: 0.9231\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 0s 258us/step - loss: 0.3347 - acc: 0.8970 - val_loss: 0.2593 - val_acc: 0.9219\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 0s 262us/step - loss: 0.3779 - acc: 0.8810 - val_loss: 0.2591 - val_acc: 0.9238\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 0s 270us/step - loss: 0.3617 - acc: 0.8830 - val_loss: 0.2541 - val_acc: 0.9223\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 0s 258us/step - loss: 0.3616 - acc: 0.8850 - val_loss: 0.2521 - val_acc: 0.9225\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 0s 260us/step - loss: 0.3358 - acc: 0.8990 - val_loss: 0.2529 - val_acc: 0.9234\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 0s 257us/step - loss: 0.3692 - acc: 0.8880 - val_loss: 0.2533 - val_acc: 0.9221\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 0s 257us/step - loss: 0.3409 - acc: 0.8880 - val_loss: 0.2567 - val_acc: 0.9230\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 0s 256us/step - loss: 0.3537 - acc: 0.8880 - val_loss: 0.2522 - val_acc: 0.9234\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 0s 262us/step - loss: 0.3286 - acc: 0.8930 - val_loss: 0.2508 - val_acc: 0.9237\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 0s 273us/step - loss: 0.3171 - acc: 0.9000 - val_loss: 0.2464 - val_acc: 0.9244\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 0s 259us/step - loss: 0.2923 - acc: 0.9090 - val_loss: 0.2447 - val_acc: 0.9243\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 0s 264us/step - loss: 0.3462 - acc: 0.8880 - val_loss: 0.2465 - val_acc: 0.9242\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 0s 256us/step - loss: 0.3492 - acc: 0.8810 - val_loss: 0.2542 - val_acc: 0.9201\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 0s 263us/step - loss: 0.3401 - acc: 0.8870 - val_loss: 0.2439 - val_acc: 0.9251\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 0s 255us/step - loss: 0.3638 - acc: 0.8890 - val_loss: 0.2440 - val_acc: 0.9255\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 0s 261us/step - loss: 0.3498 - acc: 0.8770 - val_loss: 0.2477 - val_acc: 0.9222\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 0s 258us/step - loss: 0.3257 - acc: 0.9000 - val_loss: 0.2470 - val_acc: 0.9264\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 0s 261us/step - loss: 0.3405 - acc: 0.8940 - val_loss: 0.2499 - val_acc: 0.9226\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 0s 258us/step - loss: 0.3220 - acc: 0.8920 - val_loss: 0.2557 - val_acc: 0.9225\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 0s 259us/step - loss: 0.3480 - acc: 0.8890 - val_loss: 0.2529 - val_acc: 0.9212\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 0s 255us/step - loss: 0.3234 - acc: 0.9040 - val_loss: 0.2439 - val_acc: 0.9239\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 0s 261us/step - loss: 0.3152 - acc: 0.9030 - val_loss: 0.2488 - val_acc: 0.9211\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 0s 258us/step - loss: 0.3230 - acc: 0.8910 - val_loss: 0.2512 - val_acc: 0.9210\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 0s 262us/step - loss: 0.3121 - acc: 0.9060 - val_loss: 0.2400 - val_acc: 0.9250\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 0s 260us/step - loss: 0.2973 - acc: 0.9000 - val_loss: 0.2441 - val_acc: 0.9243\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 0s 257us/step - loss: 0.3129 - acc: 0.9030 - val_loss: 0.2440 - val_acc: 0.9214\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 0s 260us/step - loss: 0.3066 - acc: 0.9000 - val_loss: 0.2386 - val_acc: 0.9275\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 0s 259us/step - loss: 0.2891 - acc: 0.9170 - val_loss: 0.2497 - val_acc: 0.9202\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 0s 256us/step - loss: 0.3294 - acc: 0.8860 - val_loss: 0.2424 - val_acc: 0.9235\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 0s 265us/step - loss: 0.3022 - acc: 0.8940 - val_loss: 0.2387 - val_acc: 0.9246\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 0s 266us/step - loss: 0.3002 - acc: 0.8990 - val_loss: 0.2373 - val_acc: 0.9260\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 0s 266us/step - loss: 0.3142 - acc: 0.8950 - val_loss: 0.2394 - val_acc: 0.9237\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 0s 268us/step - loss: 0.3217 - acc: 0.8930 - val_loss: 0.2383 - val_acc: 0.9272\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 266us/step - loss: 0.2824 - acc: 0.9070 - val_loss: 0.2335 - val_acc: 0.9276\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 0s 276us/step - loss: 0.3002 - acc: 0.9150 - val_loss: 0.2347 - val_acc: 0.9281\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 0s 263us/step - loss: 0.3196 - acc: 0.8950 - val_loss: 0.2393 - val_acc: 0.9248\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 0s 274us/step - loss: 0.2881 - acc: 0.9120 - val_loss: 0.2353 - val_acc: 0.9263\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 0s 270us/step - loss: 0.3025 - acc: 0.9170 - val_loss: 0.2360 - val_acc: 0.9287\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 0s 272us/step - loss: 0.2957 - acc: 0.9070 - val_loss: 0.2346 - val_acc: 0.9257\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 0s 274us/step - loss: 0.3133 - acc: 0.8960 - val_loss: 0.2301 - val_acc: 0.9288\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 0s 276us/step - loss: 0.2721 - acc: 0.9050 - val_loss: 0.2326 - val_acc: 0.9281\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 0s 262us/step - loss: 0.2986 - acc: 0.8970 - val_loss: 0.2330 - val_acc: 0.9275\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 0s 272us/step - loss: 0.3142 - acc: 0.8960 - val_loss: 0.2411 - val_acc: 0.9229\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 0s 261us/step - loss: 0.2883 - acc: 0.8990 - val_loss: 0.2338 - val_acc: 0.9270\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 0s 266us/step - loss: 0.2828 - acc: 0.9150 - val_loss: 0.2388 - val_acc: 0.9266\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 0s 255us/step - loss: 0.2704 - acc: 0.9130 - val_loss: 0.2399 - val_acc: 0.9205\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 0s 258us/step - loss: 0.2876 - acc: 0.9020 - val_loss: 0.2304 - val_acc: 0.9273\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 0s 259us/step - loss: 0.2594 - acc: 0.9180 - val_loss: 0.2352 - val_acc: 0.9261\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 0s 266us/step - loss: 0.2759 - acc: 0.9100 - val_loss: 0.2350 - val_acc: 0.9253\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 0s 260us/step - loss: 0.2766 - acc: 0.9200 - val_loss: 0.2316 - val_acc: 0.9237\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 0s 270us/step - loss: 0.2565 - acc: 0.9200 - val_loss: 0.2326 - val_acc: 0.9261\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 0s 268us/step - loss: 0.2788 - acc: 0.9060 - val_loss: 0.2360 - val_acc: 0.9279\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 0s 264us/step - loss: 0.2766 - acc: 0.9110 - val_loss: 0.2286 - val_acc: 0.9274\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 0s 268us/step - loss: 0.2888 - acc: 0.9000 - val_loss: 0.2370 - val_acc: 0.9228\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 0s 259us/step - loss: 0.2626 - acc: 0.9060 - val_loss: 0.2422 - val_acc: 0.9219\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 0s 263us/step - loss: 0.2889 - acc: 0.8950 - val_loss: 0.2317 - val_acc: 0.9261\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 0s 259us/step - loss: 0.2672 - acc: 0.9110 - val_loss: 0.2296 - val_acc: 0.9274\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 0s 272us/step - loss: 0.2670 - acc: 0.9080 - val_loss: 0.2230 - val_acc: 0.9309\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 0s 266us/step - loss: 0.3075 - acc: 0.8900 - val_loss: 0.2332 - val_acc: 0.9261\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 0s 259us/step - loss: 0.2554 - acc: 0.9150 - val_loss: 0.2291 - val_acc: 0.9264\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 0s 272us/step - loss: 0.2884 - acc: 0.9100 - val_loss: 0.2314 - val_acc: 0.9245\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 0s 257us/step - loss: 0.2583 - acc: 0.9130 - val_loss: 0.2297 - val_acc: 0.9258\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 0s 275us/step - loss: 0.2770 - acc: 0.9130 - val_loss: 0.2288 - val_acc: 0.9263\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 0s 265us/step - loss: 0.2497 - acc: 0.9150 - val_loss: 0.2258 - val_acc: 0.9293\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 0s 271us/step - loss: 0.2689 - acc: 0.9010 - val_loss: 0.2255 - val_acc: 0.9302\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 0s 271us/step - loss: 0.2638 - acc: 0.9120 - val_loss: 0.2239 - val_acc: 0.9290\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 0s 267us/step - loss: 0.2702 - acc: 0.9120 - val_loss: 0.2287 - val_acc: 0.9297\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 0s 256us/step - loss: 0.2767 - acc: 0.9130 - val_loss: 0.2218 - val_acc: 0.9307\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 0s 270us/step - loss: 0.2416 - acc: 0.9200 - val_loss: 0.2248 - val_acc: 0.9283\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 0s 271us/step - loss: 0.2529 - acc: 0.9140 - val_loss: 0.2228 - val_acc: 0.9306\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 0s 263us/step - loss: 0.2354 - acc: 0.9290 - val_loss: 0.2213 - val_acc: 0.9317\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 0s 258us/step - loss: 0.2450 - acc: 0.9240 - val_loss: 0.2240 - val_acc: 0.9288\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 0s 271us/step - loss: 0.2593 - acc: 0.9190 - val_loss: 0.2403 - val_acc: 0.9241\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 0s 264us/step - loss: 0.2382 - acc: 0.9140 - val_loss: 0.2241 - val_acc: 0.9285\n",
      "Epochs: 12\n",
      "Samples to train: 1000\n",
      "Test loss: 0.2240808473289013\n",
      "Test accuracy: 0.9285\n"
     ]
    }
   ],
   "source": [
    "x_train_tmp = x_train[0:1000]\n",
    "y_train_tmp = y_train[0:1000]\n",
    "\n",
    "classModel.fit(x_train_tmp, y_train_tmp,\n",
    "              batch_size=batch_size,\n",
    "              epochs=100,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))   \n",
    "    \n",
    "score = classModel.evaluate(x_test, y_test, verbose=0)\n",
    "print('Epochs:', epochs)\n",
    "print('Samples to train:', x_train_tmp.shape[0])\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.29919255  0.01709349  0.3053112   0.00155063  0.08828022\n",
      "    0.18722624 -0.17406873 -0.0623871   0.00153094  0.02996115\n",
      "   -0.11959304 -0.02224343 -0.24095383  0.18268563 -0.02146808\n",
      "   -0.08516683 -0.001798   -0.6378872  -0.14818974 -0.46854314\n",
      "   -0.66712457 -0.16254285 -0.17881007  0.12634867 -0.05036632\n",
      "   -0.08821664  0.00725421 -0.778612    0.33235785 -0.01625446\n",
      "    0.16069423 -0.12577629]]\n",
      "\n",
      " [[-0.21167481 -0.41408643 -0.32262242  0.14294715  0.16305844\n",
      "    0.33179703 -0.3587876  -0.12397511 -0.38373846 -0.80936277\n",
      "   -0.02454054  0.17845833  0.0645322   0.21386188  0.0056273\n",
      "   -0.00977601 -0.25480133 -0.6131768  -0.2643894  -0.4865285\n",
      "    0.69117105 -0.16891165 -0.28950822 -0.2052995  -0.35832945\n",
      "   -0.5820058   0.08143426 -0.34401196 -0.07202615 -0.085149\n",
      "    0.0438566  -0.6265777 ]]\n",
      "\n",
      " [[-0.00137072 -0.17525797  0.01615386  0.24336788  0.20005539\n",
      "    0.00609318 -0.13770357 -0.10311387 -0.21559714 -0.05773453\n",
      "   -0.02362541 -0.11833433 -0.18994513 -0.17465658  0.02132894\n",
      "    0.23674668 -0.00158333 -0.38294843  0.22945489  0.19636951\n",
      "    0.16586488 -0.25876004 -0.05262449 -0.04814886 -0.02251202\n",
      "   -0.88574445  0.05815336 -0.5695395   0.4139735   0.13956237\n",
      "    0.05876797 -0.3798478 ]]]\n",
      "[-0.00659493  0.00210815  0.00011995  0.00501902  0.0041117   0.0063568\n",
      " -0.00144237  0.00576794  0.00514786  0.00130889]\n"
     ]
    }
   ],
   "source": [
    "print(classModel.get_weights()[0][0])\n",
    "print(classModel.get_weights()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
